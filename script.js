// ==== script.js ====

// Au chargement de la page, on initialise lâ€™API Web Speech
const statusEl     = document.getElementById('status');
const transcriptEl = document.getElementById('transcript');

const SpeechRec = window.SpeechRecognition || window.webkitSpeechRecognition;
const recog     = new SpeechRec();
recog.lang      = 'fr-FR';
recog.interimResults = false;
recog.continuous      = true;

const synth = window.speechSynthesis;

// Quand la reconnaissance dÃ©marre
recog.onstart = () => {
  statusEl.textContent = 'ðŸŸ¢ Roby Ã©couteâ€¦';
};

// Ã€ lâ€™Ã©coute dâ€™un rÃ©sultat
recog.onresult = async (event) => {
  const userText = event.results[0][0].transcript.trim();
  transcriptEl.textContent = `ðŸŸ¡ Tu as dit : Â« ${userText} Â»`;

  try {
    const response = await fetch('/.netlify/functions/openai', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message: userText })
    });
    const data = await response.json();
    const botReply = data.choices[0].message.content.trim();

    // Lecture vocale de la rÃ©ponse
    const utter = new SpeechSynthesisUtterance(botReply);
    utter.lang = 'fr-FR';
    utter.onend = () => recog.start();  // relance lâ€™Ã©coute
    synth.speak(utter);
  } catch (err) {
    console.error(err);
    statusEl.textContent = 'âŒ Erreur de communication.';
    // on retente aprÃ¨s 2s
    setTimeout(() => recog.start(), 2000);
  }
};

// Si erreur systÃ¨me
recog.onerror = () => {
  statusEl.textContent = 'âš ï¸ ProblÃ¨me de reconnaissance.';
  recog.start();
};

// On lance immÃ©diatement lâ€™Ã©coute continue
window.addEventListener('load', () => {
  recog.start();
});
